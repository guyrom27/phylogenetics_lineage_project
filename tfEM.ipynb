{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is from https://github.com/aakhundov/tf-example-models\n",
    "import matplotlib.patches as pat\n",
    "DIMENSIONS = 2\n",
    "COMPONENTS = 3\n",
    "DATA_POINTS = 300\n",
    "EM_STEPS = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_covariances(components, dimensions, diagonal=False, isotropic=False):\n",
    "    \"\"\"Generates a batch of random positive definite covariance matrices\"\"\"\n",
    "    covariances = np.zeros((components, dimensions, dimensions))\n",
    "\n",
    "    if isotropic:\n",
    "        for i in range(components):\n",
    "            covariances[i] = np.diag(np.full((dimensions,), np.abs(np.random.normal())))\n",
    "    elif diagonal:\n",
    "        for i in range(components):\n",
    "            covariances[i] = np.diag(np.abs(np.random.normal(size=[dimensions])))\n",
    "    else:\n",
    "        for i in range(components):\n",
    "            covariances[i] = np.random.normal(size=[dimensions, dimensions])\n",
    "            covariances[i] = np.dot(covariances[i], covariances[i].T)\n",
    "\n",
    "    return covariances\n",
    "\n",
    "\n",
    "def generate_gmm_data(size, components, dimensions, seed=None, diagonal=False, isotropic=False, nan_fraction=0):\n",
    "    \"\"\"Generates synthetic data of a given size from a random Gaussian Mixture Model,\n",
    "    non_franction is the fraction of the elements that should be nan\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    means = np.random.normal(size=[components, dimensions]) * 10\n",
    "    covariances = _generate_covariances(components, dimensions, diagonal, isotropic)\n",
    "    weights = np.ones(components)/components\n",
    "    #weights = np.abs(np.random.normal(size=[components]))\n",
    "    #weights /= np.sum(weights)\n",
    "\n",
    "    \n",
    "    result = np.empty((size, dimensions), dtype=np.float32)\n",
    "    responsibilities = np.empty((size,), dtype=np.int32)\n",
    "\n",
    "    for i in range(size):\n",
    "        comp = np.random.choice(components, p=weights)\n",
    "\n",
    "        responsibilities[i] = comp\n",
    "        result[i] = np.random.multivariate_normal(\n",
    "            means[comp], covariances[comp]\n",
    "        )\n",
    "    \n",
    "    result.ravel()[np.random.choice(result.size, int(nan_fraction*result.size), replace=False)] = np.nan\n",
    "    \n",
    "    np.random.seed()\n",
    "\n",
    "    return result, means, covariances, weights, responsibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is from https://github.com/aakhundov/tf-example-models\n",
    "def _plot_gaussian(mean, covariance, color, zorder=0):\n",
    "    \"\"\"Plots the mean and 2-std ellipse of a given Gaussian\"\"\"\n",
    "    plt.plot(mean[0], mean[1], color[0] + \".\", zorder=zorder)\n",
    "\n",
    "    if covariance.ndim == 1:\n",
    "        covariance = np.diag(covariance)\n",
    "\n",
    "    radius = np.sqrt(5.991)\n",
    "    eigvals, eigvecs = np.linalg.eig(covariance)\n",
    "    axis = np.sqrt(eigvals) * radius\n",
    "    slope = eigvecs[1][0] / eigvecs[1][1]\n",
    "    angle = 180.0 * np.arctan(slope) / np.pi\n",
    "\n",
    "    plt.axes().add_artist(pat.Ellipse(\n",
    "        mean, 2 * axis[0], 2 * axis[1], angle=angle,\n",
    "        fill=False, color=color, linewidth=1, zorder=zorder\n",
    "    ))\n",
    "\n",
    "\n",
    "def plot_fitted_data(data, means, covariances, true_means=None, true_covariances=None):\n",
    "    \"\"\"Plots the data and given Gaussian components\"\"\"\n",
    "    plt.plot(data[:, 0], data[:, 1], \"b.\", markersize=0.5, zorder=0)\n",
    "\n",
    "    if true_means is not None:\n",
    "        for i in range(len(true_means)):\n",
    "            _plot_gaussian(true_means[i], true_covariances[i], \"green\", 1)\n",
    "\n",
    "    for i in range(len(means)):\n",
    "        _plot_gaussian(means[i], covariances[i], \"red\", 2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_means(x):\n",
    "    # TODO resample at each step s.t. it won't try to effect the specific X values we choose as means\n",
    "    #rand_point_ids = tf.squeeze(tf.multinomial(tf.ones([1, tf.shape(x)[0]]), COMPONENTS))\n",
    "    #return tf.Variable(tf.gather(x, rand_point_ids), dtype=tf.float32, name='initial_means', trainable=False)\n",
    "    return tf.Variable(tf.gather(x, [1,2,8]), dtype=tf.float32, name='initial_means', trainable=False)\n",
    "\n",
    "def initial_covariances(x):\n",
    "    # computing input statistics\n",
    "    #dim_means = tf.reduce_mean(x, 0)\n",
    "    #dim_distances = tf.squared_difference(x, tf.expand_dims(dim_means, 0))\n",
    "    #dim_variances = tf.reduce_sum(dim_distances, 0) / tf.cast(tf.shape(x)[0], tf.float32)\n",
    "    #avg_variance = tf.cast(tf.reduce_sum(dim_variances) / DIMENSIONS**2, tf.float32)\n",
    "    #return tf.Variable(tf.cast(tf.ones([COMPONENTS, DIMENSIONS,DIMENSIONS]), tf.float32) * avg_variance, name='initial_variances', trainable=False)\n",
    "    return tf.Variable(tf.tile(tf.reshape(10*tf.eye(DIMENSIONS, dtype=tf.float32),(1,DIMENSIONS,DIMENSIONS)),[COMPONENTS,1,1]), name='initial_variances', trainable=False)\n",
    "\n",
    "def initial_alphas():\n",
    "    return tf.Variable(tf.cast(tf.fill([COMPONENTS], 1. / COMPONENTS), tf.float32), name='initial_alphas', trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NP\n",
    "def initial_means(x):\n",
    "    # TODO resample at each step s.t. it won't try to effect the specific X values we choose as means\n",
    "    #rand_point_ids = tf.squeeze(tf.multinomial(tf.ones([1, tf.shape(x)[0]]), COMPONENTS))\n",
    "    #return tf.Variable(tf.gather(x, rand_point_ids), dtype=tf.float32, name='initial_means', trainable=False)\n",
    "    return x[[0,1,2],:]\n",
    "\n",
    "def initial_covariances(x):\n",
    "    # computing input statistics\n",
    "    #dim_means = tf.reduce_mean(x, 0)\n",
    "    #dim_distances = tf.squared_difference(x, tf.expand_dims(dim_means, 0))\n",
    "    #dim_variances = tf.reduce_sum(dim_distances, 0) / tf.cast(tf.shape(x)[0], tf.float32)\n",
    "    #avg_variance = tf.cast(tf.reduce_sum(dim_variances) / DIMENSIONS**2, tf.float32)\n",
    "    #return tf.Variable(tf.cast(tf.ones([COMPONENTS, DIMENSIONS,DIMENSIONS]), tf.float32) * avg_variance, name='initial_variances', trainable=False)\n",
    "    return np.tile(np.reshape(10*np.eye(DIMENSIONS, dtype=np.float32),(1,DIMENSIONS,DIMENSIONS)),[COMPONENTS,1,1])\n",
    "\n",
    "def initial_alphas():\n",
    "    return np.ones(COMPONENTS) * (1. / COMPONENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NP\n",
    "def p_k(x, means, covariances):\n",
    "    import numpy as tf\n",
    "    tf.reduce_mean = tf.mean\n",
    "    tf.reduce_sum = tf.sum\n",
    "    x_minus_mu = tf.expand_dims(x,0)-tf.expand_dims(means,1)\n",
    "    inv_sigma = tf.linalg.inv(covariances)\n",
    "    exponent=-1/2*tf.einsum('cbi,cij,cbj->bc', x_minus_mu, inv_sigma, x_minus_mu)\n",
    "    unnormalized_pdf = tf.exp(exponent)\n",
    "    tmp = tf.linalg.det(covariances)\n",
    "    normalizing_constant = ((2*math.pi)**(DIMENSIONS/2)) * tf.sqrt(tmp)\n",
    "    return unnormalized_pdf/normalizing_constant\n",
    "\n",
    "def reweights(p_k, alphas):\n",
    "    import numpy as tf\n",
    "    tf.reduce_mean = tf.mean\n",
    "    tf.reduce_sum = tf.sum\n",
    "    nominator = p_k*alphas\n",
    "    return nominator/tf.linalg.norm(nominator, ord=1, axis=1, keepdims=True)\n",
    "\n",
    "def realphas(weights):\n",
    "    import numpy as tf\n",
    "    tf.reduce_mean = tf.mean\n",
    "    tf.reduce_sum = tf.sum\n",
    "    return tf.reduce_mean(weights,axis=0)\n",
    "def remeans(x, weights):\n",
    "    import numpy as tf\n",
    "    tf.reduce_mean = tf.mean\n",
    "    tf.reduce_sum = tf.sum\n",
    "    tf.is_nan = tf.isnan\n",
    "    nan_mask = tf.tile(tf.expand_dims(tf.is_nan(x),1),(1,COMPONENTS,1))\n",
    "    zeros_mat = tf.zeros_like(nan_mask, dtype=tf.float32)\n",
    "\n",
    "    expanded_weights = tf.tile(tf.expand_dims(weights,2), (1,1,DIMENSIONS))\n",
    "    masked_weights = tf.where(nan_mask, zeros_mat, expanded_weights)\n",
    "\n",
    "    weighted_x = masked_weights*x\n",
    "    weighted_x_no_nan = tf.where(nan_mask, zeros_mat, weighted_x)\n",
    "\n",
    "    nan_aware_normalization = tf.reduce_sum(masked_weights,axis=0)\n",
    "\n",
    "    return tf.reduce_mean(weighted_x_no_nan,axis=0)/nan_aware_normalization\n",
    "def recovariances(x,means,weights):\n",
    "    import numpy as tf\n",
    "    tf.reduce_mean = tf.mean\n",
    "    tf.reduce_sum = tf.sum\n",
    "    tf.is_nan = tf.isnan\n",
    "    x_minus_mu_with_nans = tf.expand_dims(x,0)-tf.expand_dims(means,1)\n",
    "    x_minus_mu = tf.where(tf.is_nan(x_minus_mu_with_nans), tf.zeros_like(x_minus_mu_with_nans), x_minus_mu_with_nans)\n",
    "    x_xT = tf.einsum('cbi,cbj->bcij', x_minus_mu, x_minus_mu)\n",
    "    nan_mask = tf.is_nan(x_xT)\n",
    "    expanded_weights = tf.tile(tf.expand_dims(tf.expand_dims(weights,2),3),(1,1,DIMENSIONS,DIMENSIONS))\n",
    "\n",
    "    weighted_covariances = expanded_weights*x_xT\n",
    "    zero_mat = tf.zeros_like(nan_mask, dtype=tf.float32)\n",
    "\n",
    "    unnormalized_covariances = tf.reduce_sum(tf.where(nan_mask, zero_mat, weighted_covariances),axis=0)\n",
    "    nan_aware_normalization = tf.reduce_sum(tf.where(nan_mask, zero_mat, expanded_weights),axis=0)\n",
    "    return unnormalized_covariances/nan_aware_normalization\n",
    "\n",
    "\n",
    "#sig_mu = tf.einsum('c,bc,cbi,cbj->cij', (1/tf.reduce_sum(weights,axis=0)),weights,x_minus_mu,x_minus_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init_mu, init_sig, init_alpha = initial_means(xx), initial_covariances(xx), initial_alphas()\n",
    "mu, sig, alpha = init_mu, init_sig, init_alpha\n",
    "for i in range(EM_STEPS):\n",
    "    w = Expectation(xx, mu, sig, alpha)\n",
    "    \n",
    "    alpha = realphas(w)\n",
    "    mu  = remeans(xx, w)\n",
    "    sig = recovariances(xx, mu, w)\n",
    "    \n",
    "    plot_fitted_data(\n",
    "    xx[:, :2], mu[:, :2], sig[:, :2, :2],\n",
    "    true_means[:, :2], true_variances[:, :2, :2]\n",
    "    )\n",
    "    print(mu)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_k(x, means, covariances):\n",
    "    \"\"\"using the marginal probability of the non-nan values. \n",
    "    This is performed by replacing the nan with 0 after calculating x-mu,\n",
    "    which corresponds to looking at the sub covariance matrix that only has the non nan dimensions,\n",
    "    which is the marginal probability of the observed values of the point\n",
    "    \"\"\"\n",
    "    x_minus_mu_with_nans = tf.expand_dims(x,0)-tf.expand_dims(means,1)\n",
    "    x_minus_mu = tf.where(tf.is_nan(x_minus_mu_with_nans), tf.zeros_like(x_minus_mu_with_nans), x_minus_mu_with_nans)\n",
    "    inv_sigma = tf.linalg.inv(covariances)\n",
    "    exponent=-1/2*tf.einsum('cbi,cij,cbj->bc', x_minus_mu, inv_sigma, x_minus_mu)\n",
    "    unnormalized_pdf = tf.exp(exponent)\n",
    "    normalizing_constant = ((2*math.pi)**(DIMENSIONS/2)) * tf.sqrt(tf.linalg.det(covariances))\n",
    "    return unnormalized_pdf/normalizing_constant\n",
    "\n",
    "def reweights(p_k, alphas):\n",
    "    nominator = p_k*alphas\n",
    "    return nominator/tf.linalg.norm(nominator, ord=1, axis=1, keepdims=True)\n",
    "\n",
    "def realphas(weights):\n",
    "    return tf.reduce_mean(weights,axis=0)\n",
    "\n",
    "def remeans(x, weights):\n",
    "    nan_mask = tf.tile(tf.expand_dims(tf.is_nan(x),1),(1,COMPONENTS,1))\n",
    "    zeros_mat = tf.zeros_like(nan_mask, dtype=tf.float32)\n",
    "\n",
    "    expanded_weights = tf.tile(tf.expand_dims(weights,2), (1,1,DIMENSIONS))\n",
    "    masked_weights = tf.where(nan_mask, zeros_mat, expanded_weights)\n",
    "\n",
    "    weighted_x = tf.einsum('bci,bi->bci',masked_weights,x)\n",
    "    weighted_x_no_nan = tf.where(nan_mask, zeros_mat, weighted_x)\n",
    "\n",
    "    nan_aware_normalization = tf.reduce_sum(masked_weights,axis=0)\n",
    "\n",
    "    return tf.reduce_sum(weighted_x_no_nan,axis=0)/nan_aware_normalization\n",
    "\n",
    "def recovariances(x,means,weights):\n",
    "    x_minus_mu_with_nans = tf.expand_dims(x,0)-tf.expand_dims(means,1)\n",
    "    x_minus_mu = tf.where(tf.is_nan(x_minus_mu_with_nans), tf.zeros_like(x_minus_mu_with_nans), x_minus_mu_with_nans)\n",
    "    x_xT = tf.einsum('cbi,cbj->bcij', x_minus_mu, x_minus_mu)\n",
    "    nan_mask = tf.is_nan(x_xT)\n",
    "    expanded_weights = tf.tile(tf.expand_dims(tf.expand_dims(weights,2),3),(1,1,DIMENSIONS,DIMENSIONS))\n",
    "\n",
    "    weighted_covariances = expanded_weights*x_xT\n",
    "    zero_mat = tf.zeros_like(nan_mask, dtype=tf.float32)\n",
    "\n",
    "    unnormalized_covariances = tf.reduce_sum(tf.where(nan_mask, zero_mat, weighted_covariances),axis=0)\n",
    "    nan_aware_normalization = tf.reduce_sum(tf.where(nan_mask, zero_mat, expanded_weights),axis=0)\n",
    "    return unnormalized_covariances/nan_aware_normalization\n",
    "\n",
    "\n",
    "#sig_mu = tf.einsum('c,bc,cbi,cbj->cij', (1/tf.reduce_sum(weights,axis=0)),weights,x_minus_mu,x_minus_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expectation(x, means, covariances, alphas):\n",
    "    return reweights(p_k(x,means,covariances)+1e-30, alphas)\n",
    "\n",
    "def Maximization(x, weights):\n",
    "    alphas = realphas(weights)\n",
    "    means  = remeans(x, weights)\n",
    "    covariances = recovariances(x, means, weights)\n",
    "    return (means, covariances, alphas)\n",
    "\n",
    "def one_step_EM(x, means, covariances, alphas):\n",
    "    w = Expectation(x, means, covariances, alphas)\n",
    "    new_means, new_covariances, new_alphas = Maximization(x, w)\n",
    "    return new_means, new_covariances, new_alphas, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, true_means, true_variances, true_weights, _ = generate_gmm_data(DATA_POINTS, COMPONENTS, DIMENSIONS, 20, nan_fraction=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = xx[~np.isnan(xx).all(axis=1)]\n",
    "DATA_POINTS = xx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan, -23.703028 ],\n",
       "       [  4.5267196, -22.258944 ],\n",
       "       [ 11.632245 ,   1.9581258],\n",
       "       [        nan, -24.355938 ],\n",
       "       [  3.568774 , -25.64547  ],\n",
       "       [  2.8000824,         nan],\n",
       "       [  7.2158575,   2.1039298],\n",
       "       [  9.603476 ,         nan],\n",
       "       [ -9.76468  ,   6.1456556],\n",
       "       [  4.5526953, -22.163347 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "init_mu, init_sig, init_alpha = initial_means(xx), initial_covariances(xx), initial_alphas()\n",
    "mu, sig, alpha = init_mu, init_sig, init_alpha\n",
    "x_ph = tf.placeholder(tf.float32, [None, DIMENSIONS], name='inputTENSOR')\n",
    "\n",
    "for i in range(EM_STEPS):\n",
    "    mu, sig, alpha, _ = one_step_EM(x_ph, mu, sig, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "init_mu, init_sig, init_alpha = initial_means(xx), initial_covariances(xx), initial_alphas()\n",
    "mu, sig, alpha = init_mu, init_sig, init_alpha\n",
    "x_ph = tf.placeholder(tf.float32, [None, DIMENSIONS], name='inputTENSOR')\n",
    "\n",
    "x, means, covariances, alphas = x_ph, mu, sig, alpha\n",
    "\n",
    "pk = p_k(x,means,covariances)\n",
    "w = reweights(pk+1e-20, alphas)\n",
    "\n",
    "weights = w\n",
    "alphas = realphas(weights)\n",
    "means  = remeans(x, weights)\n",
    "covariances = recovariances(x, means, weights)\n",
    "new_means, new_covariances, new_alphas = (means, covariances, alphas)\n",
    "\n",
    "\n",
    "\n",
    "mu, sig, alpha, _ =  new_means, new_covariances, new_alphas, w\n",
    "\n",
    "sess.run(tf.global_variables_initializer(), feed_dict={x_ph: xx})\n",
    "print(\"x\",xx[:9,:])\n",
    "print(\"pk\",sess.run([pk[:9,:]], feed_dict={x_ph: xx}))\n",
    "print(\"W\",sess.run([w[:9,:]], feed_dict={x_ph: xx}))\n",
    "print(\"mu0\",sess.run([init_mu], feed_dict={x_ph: xx}))\n",
    "print(\"sig0:3\",sess.run([init_sig], feed_dict={x_ph: xx}))\n",
    "print(\"true mu\",true_means)\n",
    "print(\"mu1\",sess.run([mu], feed_dict={x_ph: xx}))\n",
    "print(\"alph\",sess.run([alphas], feed_dict={x_ph: xx}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "init_mu, init_sig, init_alpha = initial_means(xx), initial_covariances(xx), initial_alphas()\n",
    "mu, sig, alpha = init_mu, init_sig, init_alpha\n",
    "x_ph = tf.placeholder(tf.float32, [None, DIMENSIONS], name='inputTENSOR')\n",
    "\n",
    "x, means, covariances, alphas = x_ph, mu, sig, alpha\n",
    "pk = p_k(x,means,covariances)\n",
    "w = reweights(pk+1e-20, alphas)\n",
    "\n",
    "weights = w\n",
    "\n",
    "nan_mask = tf.tile(tf.expand_dims(tf.is_nan(x),1),(1,COMPONENTS,1))\n",
    "zeros_mat = tf.zeros_like(nan_mask, dtype=tf.float32)\n",
    "\n",
    "expanded_weights = tf.tile(tf.expand_dims(weights,2), (1,1,DIMENSIONS))\n",
    "masked_weights = tf.where(tf.is_nan(expanded_weights), zeros_mat, expanded_weights)\n",
    "\n",
    "weighted_x = tf.einsum('bci,bi->bci',masked_weights,x)\n",
    "weighted_x_no_nan = tf.where(nan_mask, zeros_mat, weighted_x)\n",
    "\n",
    "nan_aware_normalization = tf.reduce_sum(masked_weights,axis=0)\n",
    "unnormalized = tf.reduce_sum(weighted_x_no_nan,axis=0)\n",
    "new_means = unnormalized/nan_aware_normalization\n",
    "\n",
    "prev = tf.einsum('c,bc,bi->ci', (1/tf.reduce_sum(weights,axis=0)),weights,x)\n",
    "weight_norm = (1/tf.reduce_sum(weights,axis=0))\n",
    "weighted_x1 = tf.einsum('bc,bi->ci', weights, x)\n",
    "normalized = tf.einsum('c,ci->ci', weight_norm, weighted_x1)\n",
    "sess.run(tf.global_variables_initializer(), feed_dict={x_ph: xx})\n",
    "\n",
    "print(\"x\",xx[:10,:])\n",
    "print(\"pk\", sess.run([pk[:6,:]], feed_dict={x_ph: xx}))\n",
    "\"\"\"print(\"W\",sess.run([w[:6,:]], feed_dict={x_ph: xx}))\n",
    "print(\"mu0\",sess.run([init_mu], feed_dict={x_ph: xx}))\n",
    "print(\"sig0:3\",sess.run([init_sig], feed_dict={x_ph: xx}))\n",
    "print(\"true mu\",true_means)\n",
    "\"\"\"\n",
    "print(\"mu1\",sess.run([new_means], feed_dict={x_ph: xx}))\n",
    "print(\"prev\",sess.run([prev], feed_dict={x_ph: xx}))\n",
    "\n",
    "\n",
    "print(\"masked_weights\",sess.run([masked_weights[:9]], feed_dict={x_ph: xx}))\n",
    "print(\"weights\",sess.run([weights[:9]], feed_dict={x_ph: xx}))\n",
    "\n",
    "\n",
    "print(\"unnormalized\",sess.run([unnormalized[:9]], feed_dict={x_ph: xx}))\n",
    "print(\"weightedx1\",sess.run([weighted_x1[:9]], feed_dict={x_ph: xx}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_minus_mu = tf.expand_dims(x,0)-tf.expand_dims(initial_means(x),1)\n",
    "    w_mu = tf.einsum('bc,cbj->cbj', weights, x_minus_mu)\n",
    "    w_mu_muT = tf.einsum('cbj,cbi->cij', x_minus_mu, w_mu)\n",
    "    return tf.einsum('c,cij->cij', (1/tf.reduce_sum(weights,axis=0)),w_mu_muT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_ph = tf.placeholder(tf.float32, [None, DIMENSIONS], name='inputTENSOR')\n",
    "x, means, covariances, alphas = x_ph, mu, sig, alpha\n",
    "w = Expectation(x, means, covariances, alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alphas = realphas(w)\n",
    "means  = remeans(x, w)\n",
    "covariances = recovariances(x, means, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights = w\n",
    "nan_mask = tf.tile(tf.expand_dims(tf.is_nan(x),1),(1,COMPONENTS,1))\n",
    "zeros_mat = tf.zeros_like(nan_mask, dtype=tf.float32)\n",
    "\n",
    "expanded_weights = tf.tile(tf.expand_dims(weights,2), (1,1,DIMENSIONS))\n",
    "masked_weights = tf.where(nan_mask, zeros_mat, expanded_weights)\n",
    "\n",
    "weighted_x = tf.einsum('bci,bi->bci',masked_weights,x)\n",
    "weighted_x_no_nan = tf.where(nan_mask, zeros_mat, weighted_x)\n",
    "\n",
    "nan_aware_normalization = tf.reduce_sum(masked_weights,axis=0)\n",
    "\n",
    "tf.reduce_mean(weighted_x_no_nan,axis=0)/nan_aware_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(masked_weights*x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer(), feed_dict={x_ph: xx})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sess.run(tf.reduce_mean(weighted_x_no_nan,axis=0)/nan_aware_normalization, feed_dict={x_ph: xx})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_means, new_covariances, new_alphas = Maximization(x, w)\n",
    "\n",
    "new_means, new_covariances, new_alphas, w\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_means,final_covariances = sess.run([mu, sig], feed_dict={x_ph: xx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcsoft/miniconda3/envs/clpy36/lib/python3.6/site-packages/ipykernel_launcher.py:15: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fitted_data(\n",
    "    xx[:, :2], final_means[:, :2], final_covariances[:, :2, :2],\n",
    "    true_means[:, :2], true_variances[:, :2, :2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_means, final_covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_k(x, means, covariances):\n",
    "    x_minus_mu = tf.expand_dims(x,0)-tf.expand_dims(means,1)\n",
    "    inv_sigma = tf.linalg.inv(covariances)\n",
    "    exponent=-1/2*tf.einsum('cbi,cij,cbj->bc', x_minus_mu, inv_sigma, x_minus_mu)\n",
    "    unnormalized_pdf = tf.exp(exponent)\n",
    "    normalizing_constant = ((2*math.pi)**(DIMENSIONS/2)) * tf.sqrt(tf.linalg.det(covariances))\n",
    "    return unnormalized_pdf/normalizing_constant\n",
    "\n",
    "def reweights(p_k, alphas):\n",
    "    nominator = p_k*alphas\n",
    "    return nominator/tf.linalg.norm(nominator, ord=1, axis=1, keepdims=True)\n",
    "\n",
    "def realphas(weights):\n",
    "    return tf.reduce_mean(weights,axis=0)\n",
    "def remeans(x, weights):\n",
    "    return tf.einsum('c,bc,bi->ci', (1/tf.reduce_sum(weights,axis=0)),weights,x)\n",
    "def recovariances(x,means,weights):\n",
    "    x_minus_mu = tf.expand_dims(x,0)-tf.expand_dims(means,1)\n",
    "    w_mu = tf.einsum('bc,cbj->cbj', weights, x_minus_mu)\n",
    "    w_mu_muT = tf.einsum('cbj,cbi->cij', x_minus_mu, w_mu)\n",
    "    return tf.einsum('c,cij->cij', (1/tf.reduce_sum(weights,axis=0)),w_mu_muT)\n",
    "\n",
    "def Expectation(x, means, covariances, alphas):\n",
    "    return reweights(p_k(x,means,covariances), alphas)\n",
    "\n",
    "def Maximization(x, weights):\n",
    "    alphas = realphas(weights)\n",
    "    means  = remeans(x, weights)\n",
    "    covariances = recovariances(x, means, weights)\n",
    "    return (means, covariances, alphas)\n",
    "\n",
    "def one_step_EM(x, means, covariances, alphas):\n",
    "    w = Expectation(x, means, covariances, alphas)\n",
    "    new_means, new_covariances, new_alphas = Maximization(x, w)\n",
    "    return new_means, new_covariances, new_alphas, w\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "x_ph = tf.placeholder(tf.float32, [None, DIMENSIONS], name='inputTENSOR')\n",
    "init_mu, init_sig, init_alpha = initial_means(xx), initial_covariances(xx), initial_alphas()\n",
    "mu, sig, alpha = init_mu, init_sig, init_alpha\n",
    "\n",
    "for i in range(25):\n",
    "    mu, sig, alpha, _ = one_step_EM(x_ph, mu, sig, alpha)\n",
    "\n",
    "sess.run(tf.global_variables_initializer(), feed_dict={x_ph: xx})\n",
    "final_means0,final_covariances0 = sess.run([mu, sig], feed_dict={x_ph: xx})\n",
    "plot_fitted_data(\n",
    "    xx[:, :2], final_means0[:, :2], final_covariances0[:, :2, :2],\n",
    "    true_means[:, :2], true_variances[:, :2, :2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_means0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
